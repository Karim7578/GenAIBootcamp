{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 📦 **1. Setup environnement**"
      ],
      "metadata": {
        "id": "RUW8l5CPlG_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q wandb transformers==4.41.0 kaggle"
      ],
      "metadata": {
        "id": "-mo_26MOlHkt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f36d8e66-591f-42f9-e0de-44c61538a5b7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📁 **2. Téléchargement des données**\n"
      ],
      "metadata": {
        "id": "0fJj8Q9alPcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, zipfile, shutil\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd, numpy as np\n",
        "import wandb\n",
        "wandb.login()  # 🔑 Collez votre clé API quand demandé\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from transformers import BertTokenizer, BertModel, BertConfig\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "if not os.path.exists(\"llm-detect-ai-generated-text\"):\n",
        "    !kaggle competitions download -c llm-detect-ai-generated-text\n",
        "    with zipfile.ZipFile(\"llm-detect-ai-generated-text.zip\") as zf:\n",
        "        zf.extractall()\n",
        "\n",
        "TRAIN_PATH  = \"train_essays.csv\"\n",
        "TEST_PATH   = \"test_essays.csv\"\n",
        "PROMPT_PATH = \"train_prompts.csv\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "igsszCW-lPQq",
        "outputId": "0d5a09f1-1685-439d-8c44-af44617d621d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mk_benyahia\u001b[0m (\u001b[33mk_benyahia-pstb\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 4, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/__init__.py\", line 6, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 434, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.config/kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⚙️ **4. Hyper-paramètres**"
      ],
      "metadata": {
        "id": "2L2hVHv-lmjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_batch_size  = 64\n",
        "test_batch_size   = 64\n",
        "max_length        = 128\n",
        "num_hidden_layers = 2\n",
        "train_ratio       = 0.9\n",
        "nz                = 100\n",
        "lr                = 1e-4\n",
        "beta1             = 0.3\n",
        "num_epochs        = 50\n",
        "device            = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer        = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "embedding_model  = BertModel.from_pretrained(\"bert-base-uncased\").to(device).eval()"
      ],
      "metadata": {
        "id": "TTE9sIsdlmYI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📚 **5. Dataset**"
      ],
      "metadata": {
        "id": "hJGHToTrltba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_train = pd.read_csv(TRAIN_PATH)\n",
        "all_num   = len(src_train)\n",
        "train_num = int(all_num * train_ratio)\n",
        "\n",
        "class GANDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None):\n",
        "        self.texts, self.labels = texts, labels\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        if self.labels is not None:\n",
        "            return self.texts[idx], self.labels[idx]\n",
        "        else:\n",
        "            return self.texts[idx]\n",
        "\n",
        "train_ds = GANDataset(src_train[\"text\"][:train_num].tolist(), src_train[\"generated\"][:train_num].tolist())\n",
        "test_ds  = GANDataset(src_train[\"text\"][train_num:].tolist(), src_train[\"generated\"][train_num:].tolist())\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=train_batch_size, shuffle=True, drop_last=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=test_batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "zHLpC27eltRS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧠 **6. Modèles**"
      ],
      "metadata": {
        "id": "fwm31rSdl2vW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertModel\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(nn.Linear(input_dim, 512), nn.ReLU(),\n",
        "                                nn.Linear(512, 256*128), nn.ReLU())\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.ConvTranspose1d(256, 128, 4, 2, 1), nn.ReLU(),\n",
        "            nn.ConvTranspose1d(128, 64, 4, 2, 1),  nn.ReLU(),\n",
        "            nn.ConvTranspose1d(64, 768, 4, 2, 1),  nn.Tanh())\n",
        "        cfg = BertConfig(hidden_size=768, num_hidden_layers=num_hidden_layers,\n",
        "                         max_position_embeddings=max_length, vocab_size=1)\n",
        "        self.bert = BertModel(cfg, add_pooling_layer=False)\n",
        "\n",
        "    def forward(self, z):\n",
        "        x = self.fc(z).view(-1, 256, 128)\n",
        "        x = self.conv(x).transpose(1,2)[:, :max_length, :]\n",
        "        return self.bert(inputs_embeds=x).last_hidden_state\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        cfg = BertConfig(hidden_size=768, num_hidden_layers=2,\n",
        "                         max_position_embeddings=max_length, vocab_size=1)\n",
        "        self.bert = BertModel(cfg, add_pooling_layer=False)\n",
        "        self.pool = lambda h: h.mean(dim=1)\n",
        "        self.clf  = nn.Sequential(nn.Linear(768, 256), nn.ReLU(), nn.Linear(256, 1))\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        h = self.bert(inputs_embeds=x, attention_mask=mask).last_hidden_state\n",
        "        return torch.sigmoid(self.clf(self.pool(h))).squeeze(-1)\n"
      ],
      "metadata": {
        "id": "rtsMj4rsl2ce"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔧 **7. Embedder helper**"
      ],
      "metadata": {
        "id": "zjRpoLMJl9kB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed(texts):\n",
        "    enc = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=max_length)\n",
        "    ids, mask = enc[\"input_ids\"].to(device), enc[\"attention_mask\"].to(device)\n",
        "    with torch.no_grad():\n",
        "        emb = embedding_model(input_ids=ids, attention_mask=mask).last_hidden_state\n",
        "    return emb, mask"
      ],
      "metadata": {
        "id": "LyDTu8GNl9We"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🚀 **8. Entraînement avec wandb**"
      ],
      "metadata": {
        "id": "D_RtXaSSmDsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "netG = Generator(nz).to(device)\n",
        "netD = Discriminator().to(device)\n",
        "crit = nn.BCELoss()\n",
        "optD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"llm-detect-ai-gan-v3\",\n",
        "    config={\n",
        "        \"lr\": lr, \"batch_size\": train_batch_size, \"epochs\": num_epochs,\n",
        "        \"nz\": nz, \"max_len\": max_length, \"beta1\": beta1\n",
        "    }\n",
        ")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    netG.train(); netD.train()\n",
        "    for i, (texts, labels) in enumerate(train_loader):\n",
        "        emb, mask = embed(texts)\n",
        "        y = labels.float().to(device)\n",
        "\n",
        "        # Discriminateur\n",
        "        optD.zero_grad()\n",
        "        real = netD(emb, mask)\n",
        "        loss_real = crit(real, torch.full_like(y, 0.9))\n",
        "        noise = torch.randn(len(y), nz, device=device)\n",
        "        fake = netG(noise)\n",
        "        fake_mask = torch.ones(fake.size(0), fake.size(1), device=device)\n",
        "        loss_fake = crit(netD(fake.detach(), fake_mask), torch.full_like(y, 0.1))\n",
        "        lossD = loss_real + loss_fake\n",
        "        lossD.backward(); optD.step()\n",
        "\n",
        "        # Générateur\n",
        "        optG.zero_grad()\n",
        "        lossG = crit(netD(fake, fake_mask), torch.full_like(y, 0.9))\n",
        "        lossG.backward(); optG.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            wandb.log({\"epoch\": epoch, \"step\": i, \"lossD\": lossD.item(), \"lossG\": lossG.item()})\n",
        "\n",
        "    # AUC sur test\n",
        "    netD.eval(); all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in test_loader:\n",
        "            emb, mask = embed(texts)\n",
        "            preds = netD(emb, mask)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "    auc = roc_auc_score(all_labels, all_preds)\n",
        "    wandb.log({\"epoch\": epoch, \"AUC\": auc})\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "V2MQS7JjmDhK",
        "outputId": "e1480932-6626-4daf-8cad-88b0f4845807"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250725_042517-axkcja59</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/k_benyahia-pstb/llm-detect-ai-gan-v3/runs/axkcja59' target=\"_blank\">royal-puddle-7</a></strong> to <a href='https://wandb.ai/k_benyahia-pstb/llm-detect-ai-gan-v3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/k_benyahia-pstb/llm-detect-ai-gan-v3' target=\"_blank\">https://wandb.ai/k_benyahia-pstb/llm-detect-ai-gan-v3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/k_benyahia-pstb/llm-detect-ai-gan-v3/runs/axkcja59' target=\"_blank\">https://wandb.ai/k_benyahia-pstb/llm-detect-ai-gan-v3/runs/axkcja59</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC</td><td>█▅▇▅▃▇▅▅▂▁▁▂▂▅▅██▇▇▆▇▇▆▆▇▅▅▅▅▅▅▅▅▆▇▆▆▆▆▆</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lossD</td><td>▇▂▄▇▁▂▅▃▂▃▂█▄▆█▆▄▄▄▃▃▄▂▄▄▄▄▅▃▄▄▅▄▄▅▃▄▄▄▄</td></tr><tr><td>lossG</td><td>▂▃▄▃▄▅▂▁▄▁▄█▃▁▃▂▃▁▂▂▂▂▃▂▁▂▁▂▁▂▁▁▁▂▃▂▂▃▂▁</td></tr><tr><td>step</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC</td><td>0.54015</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>lossD</td><td>1.07454</td></tr><tr><td>lossG</td><td>1.19226</td></tr><tr><td>step</td><td>0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">royal-puddle-7</strong> at: <a href='https://wandb.ai/k_benyahia-pstb/llm-detect-ai-gan-v3/runs/axkcja59' target=\"_blank\">https://wandb.ai/k_benyahia-pstb/llm-detect-ai-gan-v3/runs/axkcja59</a><br> View project at: <a href='https://wandb.ai/k_benyahia-pstb/llm-detect-ai-gan-v3' target=\"_blank\">https://wandb.ai/k_benyahia-pstb/llm-detect-ai-gan-v3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250725_042517-axkcja59/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📤 **9. Inférence & soumission**"
      ],
      "metadata": {
        "id": "oBPvMfCOmOLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inférence\n",
        "netD.eval()\n",
        "test_df = pd.read_csv(TEST_PATH)\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for texts in DataLoader(GANDataset(test_df[\"text\"].tolist()), batch_size=test_batch_size):\n",
        "        emb, mask = embed(texts)\n",
        "        preds = netD(emb)\n",
        "        all_preds.extend(preds.cpu().numpy().flatten())\n",
        "\n",
        "sub = pd.DataFrame({\"id\": test_df[\"id\"], \"generated\": all_preds})\n",
        "sub.to_csv(\"submission.csv\", index=False)\n",
        "print(\"\\n📄 Aperçu submission.csv :\")\n",
        "print(sub.head())\n",
        "files.download(\"submission.csv\")"
      ],
      "metadata": {
        "id": "a_yrmj2FlDM3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "56ac4631-fde8-4ae0-883a-359c86a79f5a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📄 Aperçu submission.csv :\n",
            "         id  generated\n",
            "0  0000aaaa   0.616513\n",
            "1  1111bbbb   0.622738\n",
            "2  2222cccc   0.721280\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_40937cb2-b0ea-49d0-902d-649817ac3be3\", \"submission.csv\", 73)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}